- Results from the last run:
  - batchsize 1 didn't converge
  - rnn is much worse than lstm
  - copying matters a lot
  - workspaces and types/tokens matter similarly (both less than copying)
  - only the full model can get the dialogs perfectly right

- I ran into limits for the number of AWS instances I can run simultaneously. I opened a case. I'm not running the following settings for now:

    "--optimize --batchsize 5",
    "--optimize --batchsize 10",
    "--optimize --batchsize 20",    
    "--optimize --stepsize 0.001",
    "--optimize --stepsize 0.01",
    "--optimize --stepsize 0.1",
    "--optimize --latentdim 5",
    "--optimize --latentdim 10",
    "--optimize --latentdim 20",
    "--optimize --latentdim 30",
    "--optimize --latentdim 50",
    "--optimize --latentdim 70",
    "--optimize --latentdim 100",
    "--optimize --latentdim 120",
    "--optimize --latentdim 200",

- Initialization seems to matter quite a bit:
  
  c4large - Iteration 1880: -22416.917113308347
  c4xlarge - Iteration 1831: -3145.709649234484

- I don't see gains from using c4.xlarge. It looks like c4.large makes most sense for this sort of experiment.

- To show behavior on remotely fitted parameters, try this:

  logistician sync
  logistician run --data_readonly "./data/--optimize" -o "--behavior"
  logistician run --data_readonly "./data/--optimize" -o "--loglikelihood-train"